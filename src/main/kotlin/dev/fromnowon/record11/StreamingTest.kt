package dev.fromnowon.record11

import ai.koog.prompt.dsl.prompt
import ai.koog.prompt.streaming.StreamFrame
import dev.fromnowon.llmModel
import dev.fromnowon.singleLLMPromptExecutor

suspend fun main() {

    val prompt = prompt("æµå¼è¾“å‡º") {
        system("ä½¿ç”¨ç®€ä½“ä¸­æ–‡å›žç­”é—®é¢˜")
        user("ç®€å•ä»‹ç»ä¸€ä¸‹ koltin KMP")
    }

    singleLLMPromptExecutor.executeStreaming(prompt, llmModel)
        .collect { frame ->
            when (frame) {
                is StreamFrame.Append -> print(frame.text)
                is StreamFrame.ToolCall -> {
                    println("ðŸ”§ Tool call: ${frame.name} args=${frame.content}")
                    // Optionally parse lazily:
                    // val json = frame.contentJson
                }

                is StreamFrame.End -> println("[END] reason=${frame.finishReason}")
            }
        }

}
